{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4주차 과제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeonahkiki/GJ_AI_Academy/blob/master/4%EC%A3%BC%EC%B0%A8_%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxkL6PjwsI6L",
        "colab_type": "text"
      },
      "source": [
        "# 4주차 과제\n",
        "- 용어 정리\n",
        "- 딥러닝 강의 클론 코딩\n",
        "- 딥러닝 순전파 & 역전파 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixEtDe6_uGgI",
        "colab_type": "text"
      },
      "source": [
        "## 1. 용어 정리\n",
        "\n",
        "다음 제시된 단어의 정의(설명)를 정리하여 작성 하세요.\n",
        "\n",
        "* 2문장 이상 작성 해 주세요. \n",
        "* 주제(단어)와 크게 벗어나지만 않는다면 정답처리 됩니다.\n",
        "* 강의 뿐 아니라 기타 레퍼런스를 참고하여 작성하셔도 됩니다. (기타 레퍼런스를 참고하신 경우, 해당 레퍼런스를 정리하여 하단에 작성해 주세요.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lfwat8eurKZ",
        "colab_type": "text"
      },
      "source": [
        "__(예시)__\n",
        "### 심층 신경망\n",
        ": 입력층과 출력층 사이에 여러 개의 은닉층들로 이뤄진 인공신경망이다. 심층 신경망은 일반적으로 인공신경망과 마찬가지로 복잡한 비선형 관계들을 모델링 할 수 있다. 신층신경망의 목적은 분류 및 수치예측을 하기 위함이고 이미지 트레이닝이나 문자인식과 같은 분야에서 매우 유용하게 쓰이고 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8YJNKG_v65A",
        "colab_type": "text"
      },
      "source": [
        "### MCP 뉴런\n",
        ":  워랜 맥컬록과 월터 피츠는 처음으로 간소화된 뇌의 뉴런 개념을 발표\n",
        "- 뇌의 신경세포와 서로 연결되어 있으며 화학적, 전기적 신호를 처리하고 전달하는데 관여\n",
        "- 이러한 신경세포를 이진 출력을 내는 간단한 논리 회로로 표현\n",
        "- MCP뉴런 모델을 기반으로 퍼셉트론 학습개념이 나오게 된다.\n",
        "\n",
        "### 퍼셉트론\n",
        ":- 혭의 학습규칙 : 양쪽 뉴런이 동시에 또 반복적으로 활성화되었다면 그 뉴런사이의 연결강도가 강화된다.\n",
        "- 인력을 받아서 계산한 후 출력을 반환하는 구조로 설명\n",
        "- 뉴런이 여러개 모여 레이어를 구성한 후, 이 레이어가 다시 모여 구성된 형태\n",
        "- 하나의 뉴런을 자세히 표현  ⇒ 가중치와 활성화 함수가 숨어있는 것을 확인할 수 있음\n",
        "- 활성화 함수 : 뉴런의 출력값을 정함\n",
        "- 가중치 : 초기화를 통한 무작위 값 할당, 학습과정에서 일정한 값 수렴\n",
        "- 학습률 : 가중치 조정을 위한 하이퍼파라미터\n",
        "- 편향 : 입력으로는 늘 한쪽으로 치우쳐진 고정값\n",
        "\n",
        "    — 입력으로 받은 값이 0인 경우에 아무것도 학습하지 못하는 것을 방지해준다\n",
        "\n",
        "    — 가중치처럼 난수로 초기화되고 뉴런에 더해져서 계산됨\n",
        "- 다층퍼셉트론\n",
        "  - 은닉층을 활용하게되면 선형분류판별선을 여러개 그리는 효과를 얻으면서 XOR연산을 해결할 수 있다.\n",
        "- 파라미터개수가 많아지면서 적절한 가중치와 편향을 학습시키는 것이 어렵다\n",
        "\n",
        "    ⇒ 역전파 알고리즘 제시\n",
        "\n",
        "### 역전파\n",
        ":- 뉴런의 가중치를 효율적으로 조정하기 위하여 거꾸로 무엇인가를 전파하는 방식\n",
        "- 기존의 출력값을 지우고 새로운 출력값으로 전달\n",
        "- 출력값과 지도데이터 사이에 생기는 오차를 이용해 출력층에서 입력층 쪽으로 가중치를 조정하는 것\n",
        "- 경사하강법을 사용하는 것이기도 함\n",
        "- 손실함수가 최솟값일때의 가중치로 원래의 가중치를 조절해야함\n",
        "- 모든 입력값을 대상으로 손실함수가 최솟값일떄의 파라미터를 찾아야함\n",
        "- 입력값 각각의 손실함수를 편미분한 후 합이 0에 가까운지를 확인\n",
        "- 입력층 - 은닉층 - 출력층 순서로 진행\n",
        "- 은닉층 가중치는 은닉층 편향의 변화량에 y를 곱한값을 빼서 조정\n",
        "- 역방향 미분이라고도 함\n",
        "- 문제점 : 기울기 소멸문제\n",
        "\n",
        "    신경망이 깊어질 수록 학습이 잘 되지 않는 문제발생\n",
        "\n",
        "    — 함수 시그모이드 : 기울기가 0으로 가는 문제발생\n",
        "\n",
        "    — 함수 소프트맥스\n",
        "\n",
        "    ⇒ 가중치의 조정이 이루어지지 않음\n",
        "\n",
        "- ReLU  : 기울기 소멸문제를 ReLU활성화함수를 활용하여 어느정도 해결할 수 있다.\n",
        "\n",
        "### 강화학습\n",
        ":- 에이전트라는 존재가 환경과 상호작용\n",
        "- 보상을 최대화하는 방향으로 학습\n",
        "\n",
        "`자전거를 타는 것으로 예시`\n",
        "\n",
        "- 자전거를 타는 대상(에이전트)\n",
        "- 자전거를 타면서 얻은 상처들(패널티)\n",
        "- 자전거를 계속 연습하면서 잘타게됨(보상)\n",
        "- 다양한 시행착오를 통해 학습이 가능하며 비교적 명확한 보상을 설정할 수 있는 문제를 해결\n",
        "- 보상을 최대화하는 의사결정 전략\n",
        "- 순차적인 행동들을 알아나가는 방법\n",
        "### MDP\n",
        "\n",
        "- 상태\n",
        "- 행동\n",
        "- 보상함수\n",
        "- 상태변환확률\n",
        "- 감가율\n",
        "\n",
        "    — 0~1 사이의 값\n",
        "\n",
        "    — 1에 가까울 수록 미래의 보상에 더 많은 가중치\n",
        "\n",
        "    — 반환값(G) : 종료에서 시작으로 계산\n",
        "\n",
        "- 에이전트 :  의사결정을 하는역할\n",
        "- 환경 : 에이전트의 의사결정을 반영, 에이전트에게 반영된 정보를 주는 역할\n",
        "- 상태 : 의사결정 진행(관측값, 행동 등 가공한 정보)\n",
        "\n",
        "    — 의사결정을 하기 위한 관측값, 보상 등을 가공한 것\n",
        "\n",
        "- 행동 : 현재상태에서 취하는 행동(이산적행동, 연속적 행동)\n",
        "\n",
        "    — 이산적 행동 : 선택지가 주어짐\n",
        "\n",
        "    — 연속적 행동 : 행동마다 특정값이 주어짐\n",
        "\n",
        "- 관측 : 환경에서 제공해주는 정보\n",
        "\n",
        "    — 시각적 관측 : 현재 상태를 이미지\n",
        "\n",
        "    — 수치적 관측 : 현재상태를 수치로\n",
        "\n",
        "- 보상함수 : 에이전트가 특정상태에서 특정행동을 했을 때 보상을 받게됨\n",
        "\n",
        "    — 특정행동을 했을 때 주어지는 보상의 기댓값을 정의하는 함수\n",
        "\n",
        "- 학습의 과정 : 에피소드를 통해 얻었던 정보로 기록 업데이트 과정 반복\n",
        "- 무작위움직임 : 탐험이라는 개념 추가\n",
        "- 익숙한움직임 : 이용이라는개념추가\n",
        "\n",
        "\n",
        "### 과적합\n",
        ":overfitting이라고 하며 학습데이터를 과하게 학습시키는 경우. 이러한 경우에는 일반화가 힘들 수 있다.\n",
        "- 결정트리학습에서 너무 많은 분기를 하게 되면 과적합이 발생하게 되어\n",
        "이를 막기위해서 분기를 재조정하거나 트리의 최대깊이를 제한하게 된다.\n",
        "- K-means에서는 k값에 따라 과적합이 발생할 수도 있다.\n",
        "\n",
        "\n",
        "### 차원의 저주\n",
        ": 차원의 저주 : 고정된 크기의 훈련 데이터셋 차원이 늘어남에 따라 특성 공간이 점점 희소해지는 현상 ⇒  올바른 변수의 선택, 차수 축소기법이 필요\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-zfFXLCy6jD",
        "colab_type": "text"
      },
      "source": [
        "## 2. 딥러닝 강의 클론 코딩\n",
        "\n",
        "####__퍼셉트론 구조 구현하기__ \n",
        "딥러닝 강의(__딥러닝 원리[1] 3:15 ~ 5:15 부분__)를 보고 코드를 따라 치며 출력 결과를 만드세요.\n",
        " \n",
        "\n",
        "* 하나의 코드셀에 해당 코드를 한번에 다 적어서 실행해주세요 (__그렇게 하지 않을 경우, 아래 이미지와 같은 출력값이 나오지 않을 수 있습니다__)\n",
        "\n",
        "*__주의!__ 실제로 코딩해서 출력해보면 강의에 나온 출력 결과와 다르게 나옵니다!!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcc5mzI9oZ7r",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0cceeed0-0235-4b0f-af88-0b8c377d5b4b%2F_2020-06-09__9.35.23.png?table=block&id=88fd8912-9356-49a4-9fda-a1a63fe96ea9&width=2870&cache=v2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FBA4XTmnkkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "e67a0b2b-6dd0-42f5-c918-9fa8468a219a"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.set_random_seed(2020)\n",
        "x = 1\n",
        "y = 0\n",
        "w = tf.random.normal([1], 0, 1)\n",
        "\n",
        "import math\n",
        "def sigmoid(x):\n",
        "  return 1/(1+math.exp(-x))\n",
        "output = sigmoid(x * w)\n",
        "print(output)\n",
        "\n",
        "for i in range(1000):\n",
        "  output = sigmoid(x * w)\n",
        "  error = y - output\n",
        "  w = w + x * 0.1 * error\n",
        "\n",
        "  if i % 100 ==99:\n",
        "    print('학습 횟수:',i, \"Error:\", error, \"예측결과:\", output)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.47477188589261\n",
            "학습 횟수: 99 Error: -0.10010598284299604 예측결과: 0.10010598284299604\n",
            "학습 횟수: 199 Error: -0.05178399422833116 예측결과: 0.05178399422833116\n",
            "학습 횟수: 299 Error: -0.034590451977903586 예측결과: 0.034590451977903586\n",
            "학습 횟수: 399 Error: -0.02588962752851373 예측결과: 0.02588962752851373\n",
            "학습 횟수: 499 Error: -0.020658699939863617 예측결과: 0.020658699939863617\n",
            "학습 횟수: 599 Error: -0.017174253993457355 예측결과: 0.017174253993457355\n",
            "학습 횟수: 699 Error: -0.014689506449480992 예측결과: 0.014689506449480992\n",
            "학습 횟수: 799 Error: -0.012829497265431342 예측결과: 0.012829497265431342\n",
            "학습 횟수: 899 Error: -0.011385568271837804 예측결과: 0.011385568271837804\n",
            "학습 횟수: 999 Error: -0.010232493309882492 예측결과: 0.010232493309882492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr0HVRk8fOom",
        "colab_type": "text"
      },
      "source": [
        "## 3. 딥러닝 순전파 & 역전파 계산\n",
        "\n",
        "딥러닝 강의(__딥러닝 원리[2] 0:55 ~ 4:32 부분__)에 나오는 순전파 & 역전파 계산에 대한 문제 입니다.\n",
        "\n",
        "해당 영상과 다음 이미지를 참고하여 다음 2가지 물음에 답하세요.\n",
        "\n",
        "\n",
        "(1) 학습률이 0.2 일 경우 출력층의 노드값\n",
        "\n",
        "(2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpwPFWhOUzww",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff54dfd45-92ec-44ae-9616-6949d2484a45%2F_2020-06-10__5.22.03.png?table=block&id=ee05da89-3ceb-4ad9-a2d3-c9f68d24d1d9&width=3580&cache=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2OVY7w5U3CI",
        "colab_type": "text"
      },
      "source": [
        "## (1) 학습률이 0.2 일 경우 출력층의 노드값 : 1.6\n",
        "## (2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은? : 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgavfvqiWxBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}